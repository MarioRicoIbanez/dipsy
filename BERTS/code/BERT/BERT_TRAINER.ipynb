{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/RikoteMaster___parquet/RikoteMaster--isear_augmented-b6d7bc560c3e10d4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abdf1f2f6594087a2d555fa4f92e659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['Emotion', 'Text_processed'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Emotion', 'Text_processed'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['Emotion', 'Text_processed'],\n",
       "        num_rows: 10751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create DatasetDict\n",
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "dataset_path = 'RikoteMaster/isear_augmented'\n",
    "dataset_dict = load_dataset(dataset_path)\n",
    "\n",
    "dataset_dict = dataset_dict.remove_columns('Augmented')\n",
    "dataset_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/RikoteMaster___parquet/RikoteMaster--isear_augmented-b6d7bc560c3e10d4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-67b0a7624c7a5d2f.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/RikoteMaster___parquet/RikoteMaster--isear_augmented-b6d7bc560c3e10d4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-161de27b49f6fdea.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/RikoteMaster___parquet/RikoteMaster--isear_augmented-b6d7bc560c3e10d4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-03e305454b1bb339.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/RikoteMaster___parquet/RikoteMaster--isear_augmented-b6d7bc560c3e10d4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-161de27b49f6fdea.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/RikoteMaster___parquet/RikoteMaster--isear_augmented-b6d7bc560c3e10d4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-03e305454b1bb339.arrow\n"
     ]
    }
   ],
   "source": [
    "#charge the train datasetDict as a df\n",
    "df = dataset_dict['train'].to_pandas()\n",
    "df.head()\n",
    "#create id2label and label2id\n",
    "id2label = {i: label for i, label in enumerate(df['Emotion'].unique())}\n",
    "label2id = {label: i for i, label in enumerate(df['Emotion'].unique())}\n",
    "\n",
    "#apply label2id to the datasetDict\n",
    "dataset_dict = dataset_dict.map(lambda example: {'labels': label2id[example['Emotion']]}, remove_columns=['Emotion'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['Text_processed', 'labels'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text_processed', 'labels'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['Text_processed', 'labels'],\n",
       "        num_rows: 10751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples[\"Text_processed\"], padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db995dfeed247e5878f3c3cc3c259ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/752 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb55a178fd6469f9f651a1fdc308586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/752 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa222710e1bb4635913d2d4aafcbc4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['Text_processed', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text_processed', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['Text_processed', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = dataset_dict.map(tokenize_text, batched=True)\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/cuda/compat/lib'), PosixPath('/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"/tmp/vscode-ssh-auth-f4e7d190-bfbc-4cdb-ac1b-b6b8c0c325c1.sock\",\"/root/.gnupg/S.gpg-agent\"]')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 120\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda120_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2023-07-17 06:43:52,948] A new study created in memory with name: no-name-6ddbb2ed-b749-4d19-82ce-f10f0f1e1c41\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='3360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 155/3360 00:15 < 05:26, 9.80 it/s, Epoch 0.23/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    \n",
    "    return {'eval_accuracy': acc, 'f1': f1}\n",
    "\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\" : trial.suggest_float(\"weight_decay\", 1e-6, 1e-1, log=True),\n",
    "\n",
    "    }\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def model_init(trial):\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(id2label), ignore_mismatched_sizes=True).to(device)\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_objective(metrics):\n",
    "    \n",
    "    return metrics['eval_accuracy'] + metrics['f1']\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "output_dir = './results_searching_hyperparameters'\n",
    "logging_steps = len(dataset_dict['train']) // batch_size\n",
    "\n",
    "args = TrainingArguments( \n",
    "                        output_dir=output_dir, \n",
    "                        num_train_epochs=epochs,\n",
    "                        per_device_train_batch_size=batch_size,\n",
    "                        per_device_eval_batch_size=batch_size,\n",
    "                        evaluation_strategy='epoch',\n",
    "                        logging_steps=logging_steps,\n",
    "                        fp16=True,\n",
    "                        push_to_hub=False,\n",
    "                        # prevent saving checkpoints\n",
    "                        save_strategy=\"steps\",\n",
    "                        save_steps=int(1e9),  # a large number\n",
    "                    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=None,\n",
    "    args=args,\n",
    "    train_dataset= dataset_dict['train'],\n",
    "    eval_dataset= dataset_dict['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    model_init=model_init,\n",
    ")\n",
    "\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=optuna_hp_space,\n",
    "    n_trials=20\n",
    ")\n",
    "\n",
    "# Save best_trial to a text file\n",
    "\n",
    "best_trial_dict = {\n",
    "    'run_id': best_trial.run_id,\n",
    "    'objective': best_trial.objective,\n",
    "    'hyperparameters': best_trial.hyperparameters\n",
    "}\n",
    "\n",
    "# Save best_trial_dict to a text file\n",
    "import json\n",
    "with open('best_trial_frozen.txt', 'w') as file:\n",
    "    file.write(json.dumps(best_trial_dict, indent=4))  # indent=4 for pretty printing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 13 11:29:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN V      Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 34%   45C    P8    26W / 250W |  10004MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "|   0  NVIDIA TITAN V      Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 34%   45C    P8    26W / 250W |  10004MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/bert-base-go-emotion and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(id2label), ignore_mismatched_sizes=True)\n",
    "#freeze all the parameters except the last layer, be sure that you freeze all excepting the last layer\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "output_dir = './results_freezed'\n",
    "logging_steps = len(dataset_dict['train']) // batch_size\n",
    "args = TrainingArguments( output_dir=output_dir, \n",
    "                        num_train_epochs=epochs,\n",
    "                        learning_rate=3.562121201880562e-04,\n",
    "                        per_device_train_batch_size=batch_size,\n",
    "                        per_device_eval_batch_size=batch_size,\n",
    "                        weight_decay=0.0007924379520012866,\n",
    "                        evaluation_strategy='epoch',\n",
    "                        save_strategy='epoch',\n",
    "                        logging_steps=logging_steps,\n",
    "                        fp16=True,\n",
    "                        push_to_hub=False,\n",
    "                        load_best_model_at_end=True,\n",
    "                        metric_for_best_model='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=dataset_dict['train'],\n",
    "                  eval_dataset=dataset_dict['validation'],\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  tokenizer=tokenizer,\n",
    "                  callbacks = [EarlyStoppingCallback(early_stopping_patience=int(0.2*epochs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12096' max='20160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12096/20160 21:46 < 14:31, 9.25 it/s, Epoch 18/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.595100</td>\n",
       "      <td>1.531633</td>\n",
       "      <td>0.442819</td>\n",
       "      <td>0.430315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>1.514691</td>\n",
       "      <td>0.432181</td>\n",
       "      <td>0.420767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.581100</td>\n",
       "      <td>1.524175</td>\n",
       "      <td>0.445479</td>\n",
       "      <td>0.441161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.574300</td>\n",
       "      <td>1.530792</td>\n",
       "      <td>0.416223</td>\n",
       "      <td>0.416816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.573800</td>\n",
       "      <td>1.515810</td>\n",
       "      <td>0.445479</td>\n",
       "      <td>0.433519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.565500</td>\n",
       "      <td>1.509822</td>\n",
       "      <td>0.448138</td>\n",
       "      <td>0.438635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.563100</td>\n",
       "      <td>1.502079</td>\n",
       "      <td>0.465426</td>\n",
       "      <td>0.452725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.558000</td>\n",
       "      <td>1.511683</td>\n",
       "      <td>0.464096</td>\n",
       "      <td>0.454242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.546200</td>\n",
       "      <td>1.491038</td>\n",
       "      <td>0.462766</td>\n",
       "      <td>0.455032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.551900</td>\n",
       "      <td>1.495883</td>\n",
       "      <td>0.458777</td>\n",
       "      <td>0.445807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.548900</td>\n",
       "      <td>1.491245</td>\n",
       "      <td>0.444149</td>\n",
       "      <td>0.436127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.548100</td>\n",
       "      <td>1.489481</td>\n",
       "      <td>0.469415</td>\n",
       "      <td>0.462042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.549200</td>\n",
       "      <td>1.503610</td>\n",
       "      <td>0.445479</td>\n",
       "      <td>0.430633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.542600</td>\n",
       "      <td>1.487946</td>\n",
       "      <td>0.442819</td>\n",
       "      <td>0.437021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.531900</td>\n",
       "      <td>1.495064</td>\n",
       "      <td>0.450798</td>\n",
       "      <td>0.439247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.541800</td>\n",
       "      <td>1.490163</td>\n",
       "      <td>0.448138</td>\n",
       "      <td>0.442986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.536000</td>\n",
       "      <td>1.497176</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.426565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.533600</td>\n",
       "      <td>1.491753</td>\n",
       "      <td>0.456117</td>\n",
       "      <td>0.448581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12096, training_loss=1.5571194822510714, metrics={'train_runtime': 1307.1586, 'train_samples_per_second': 246.741, 'train_steps_per_second': 15.423, 'total_flos': 5.09190110148096e+16, 'train_loss': 1.5571194822510714, 'epoch': 18.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mriciba/Projects/dipsy/BERTS/code/BERT/./results_freezed is already a clone of https://huggingface.co/RikoteMaster/results_freezed. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3533c84a114271903b53d8bce27f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ed69a31eec4570b1725adcc93c342b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Jul13_12-41-57_2bfb4451df90/events.out.tfevents.1689252118.2bfb4451df90.283443.21:   0%|     â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7123fca92b4ebc99af5069f2f25197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/RikoteMaster/results_freezed\n",
      "   f0a7fe0..3799876  main -> main\n",
      "\n",
      "To https://huggingface.co/RikoteMaster/results_freezed\n",
      "   3799876..2563c18  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/RikoteMaster/results_freezed/commit/37998761a70e46bb59eb1487e7155648e5274438'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#push to hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test set\n",
    "preds = trainer.predict(dataset_dict['test'])\n",
    "preds = preds.predictions.argmax(-1)\n",
    "#calculate accuracy\n",
    "acc = accuracy_score(test_df['Emotion'], preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.encoder.layer[-2:].parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
