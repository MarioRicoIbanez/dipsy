{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59519a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.28.0.dev0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2023.5.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-ha5yu1ns\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-ha5yu1ns\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 06fd06a4d2e8ed8c3a253c67d9c3cb23e0f497ad\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (4.28.0.dev0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (0.18.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.8/dist-packages (from peft==0.4.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.4.0.dev0) (68.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.4.0.dev0) (0.40.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (3.26.4)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.4.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.4.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.4.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.4.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->peft==0.4.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.4.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.4.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.4.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0.dev0) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.8/dist-packages (0.37.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install git+https://github.com/huggingface/peft.git\n",
    "!pip install bitsandbytes\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d20954",
   "metadata": {},
   "source": [
    "## Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c5741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 120\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda120_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib'), PosixPath('/usr/local/cuda/compat/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"/tmp/vscode-ssh-auth-ee4e0578-5c9f-49e9-a427-cda4de09b105.sock\",\"/root/.gnupg/S.gpg-agent\"]')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#General imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gdown \n",
    "import os\n",
    "import requests\n",
    "import string\n",
    "import re \n",
    "import shutil\n",
    "from utils import *\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "#Related to transformers and models\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "#Result imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#GENERAL CONSTANTS\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a395184",
   "metadata": {},
   "source": [
    "## Descarga del modelo a fine tunear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a37be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "modelo_base  = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463d724",
   "metadata": {},
   "source": [
    "## Descarga y tratamiento de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58204f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "      <td>on days when i feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "      <td>every time i imagine that someone i love or i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "      <td>when i had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "      <td>when i think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "      <td>at a gathering i found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>shame</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>shame</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>fear</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>guilt</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>fear</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Emotion                                               Text  \\\n",
       "0         joy  On days when I feel close to my partner and ot...   \n",
       "1        fear  Every time I imagine that someone I love or I ...   \n",
       "2       anger  When I had been obviously unjustly treated and...   \n",
       "3     sadness  When I think about the short time that we live...   \n",
       "4     disgust  At a gathering I found myself involuntarily si...   \n",
       "...       ...                                                ...   \n",
       "7511    shame  Two years back someone invited me to be the tu...   \n",
       "7512    shame  I had taken the responsibility to do something...   \n",
       "7513     fear  I was at home and I heard a loud sound of spit...   \n",
       "7514    guilt  I did not do the homework that the teacher had...   \n",
       "7515     fear  I had shouted at my younger brother and he was...   \n",
       "\n",
       "                                         Text_processed  \n",
       "0     on days when i feel close to my partner and ot...  \n",
       "1     every time i imagine that someone i love or i ...  \n",
       "2     when i had been obviously unjustly treated and...  \n",
       "3     when i think about the short time that we live...  \n",
       "4     at a gathering i found myself involuntarily si...  \n",
       "...                                                 ...  \n",
       "7511  two years back someone invited me to be the tu...  \n",
       "7512  i had taken the responsibility to do something...  \n",
       "7513  i was at home and i heard a loud sound of spit...  \n",
       "7514  i did not do the homework that the teacher had...  \n",
       "7515  i had shouted at my younger brother and he was...  \n",
       "\n",
       "[7516 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fichero se encuentra en enlace externo\n",
    "url = \"https://raw.githubusercontent.com/PoorvaRane/Emotion-Detector/master/ISEAR.csv\"\n",
    "output_file = \"ISEAR.csv\"\n",
    "\n",
    "destination_folder = \"data\"\n",
    "#Si no existe la carpeta en la que queremos guardar los datos debemos crearla\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(output_file, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "shutil.move(output_file, f\"{destination_folder}/{output_file}\")\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "df = load_and_preprocess_data('./data/ISEAR.csv')\n",
    "df['Emotion'] = df['Emotion'].replace('guit', 'guilt')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91171df0",
   "metadata": {},
   "source": [
    "## Probamos el modelo a ver de cuantas clases dispone  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e15b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'admiration', 'score': 0.0022283862344920635}, {'label': 'amusement', 'score': 0.00207656342536211}, {'label': 'anger', 'score': 0.6765081286430359}, {'label': 'annoyance', 'score': 0.11713651567697525}, {'label': 'approval', 'score': 0.006938391365110874}, {'label': 'caring', 'score': 0.008048061281442642}, {'label': 'confusion', 'score': 0.0015102234901860356}, {'label': 'curiosity', 'score': 0.0022445875220000744}, {'label': 'desire', 'score': 0.0015093624824658036}, {'label': 'disappointment', 'score': 0.018241364508867264}, {'label': 'disapproval', 'score': 0.016932494938373566}, {'label': 'disgust', 'score': 0.04833042994141579}, {'label': 'embarrassment', 'score': 0.0041035753674805164}, {'label': 'excitement', 'score': 0.002686750376597047}, {'label': 'fear', 'score': 0.0032824971713125706}, {'label': 'gratitude', 'score': 0.0020939591340720654}, {'label': 'grief', 'score': 0.002857409417629242}, {'label': 'joy', 'score': 0.0016693678917363286}, {'label': 'love', 'score': 0.0010952280135825276}, {'label': 'nervousness', 'score': 0.002996481955051422}, {'label': 'optimism', 'score': 0.0016878662863746285}, {'label': 'pride', 'score': 0.0007378275040537119}, {'label': 'realization', 'score': 0.003398278495296836}, {'label': 'relief', 'score': 0.0007681022398173809}, {'label': 'remorse', 'score': 0.0033701001666486263}, {'label': 'sadness', 'score': 0.016302889212965965}, {'label': 'surprise', 'score': 0.003571051638573408}, {'label': 'neutral', 'score': 0.04767394810914993}]]\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = TextClassificationPipeline(model=modelo_base, tokenizer=tokenizer, return_all_scores=True)\n",
    "resultados = pipe(\"fuck you leave me alone\")\n",
    "print(resultados)\n",
    "accum = 0\n",
    "for elemento in resultados: \n",
    "    for cuenta in elemento:\n",
    "        accum = accum + 1 \n",
    "print(accum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe46ed0d",
   "metadata": {},
   "source": [
    "Como observamos en este modelo se tienen 28 clases (clásico del dataset de goemotion), ahora tenemos varias opciones, podemos intentar modificar esta ultima capa para poder trabajar con los logits, lo cual numéricamente es más estable o añadir una capa final de clasificación después de esta para clasificar entre las emociones de ekman que estamos utilizando en nuestro estudio. \n",
    "\n",
    "No sabemos el método que han usado para clasificar las emociones. Por tanto lo primero que vamos a hacer va a ser realizar un entrenamiento básico añadiendo una capa final para clasificar lo que nos interesa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4505b",
   "metadata": {},
   "source": [
    "## Exploración del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c5fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"bhadresh-savani/bert-base-go-emotion\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMultilabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(modelo_base.config)\n",
    "print(modelo_base.num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f0456",
   "metadata": {},
   "source": [
    "El objeto `BertConfig` contiene los parámetros y configuraciones necesarios para el modelo BERT utilizado en la clasificación de secuencias con múltiples etiquetas. A continuación se presenta una explicación de los campos clave en la configuración:\n",
    "\n",
    "- `hidden_size` y `num_attention_heads`: Estos parámetros determinan la dimensionalidad de los vectores ocultos y el número de cabezas de atención en el modelo BERT, respectivamente.\n",
    "\n",
    "- `num_hidden_layers`: Indica el número de capas ocultas en el modelo. Aumentar este valor puede aumentar la capacidad del modelo para aprender representaciones más complejas.\n",
    "\n",
    "- `dropout`: Controla la tasa de abandono (dropout) aplicada a las salidas de las capas ocultas para evitar el sobreajuste y mejorar la generalización.\n",
    "\n",
    "- `initializer_range`: Especifica el rango de inicialización para los pesos del modelo.\n",
    "\n",
    "- `max_position_embeddings`: Define la longitud máxima permitida de las secuencias de entrada.\n",
    "\n",
    "- `vocab_size`: Indica el tamaño del vocabulario utilizado por el modelo.\n",
    "\n",
    "Estos campos son cruciales para configurar correctamente el modelo BERT en la clasificación de secuencias con múltiples etiquetas. Sin embargo, también debemos considerar otros aspectos como el modelo preentrenado, el conjunto de datos y los hiperparámetros específicos del entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc9d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2273, -4.7028, -5.9401, -5.2675, -3.2153, -4.5923, -5.4052, -4.9632,\n",
      "         -4.6493, -5.4046, -5.5101, -6.3988, -6.0861, -3.6266, -6.5459, -4.0359,\n",
      "         -7.2671, -2.7496,  1.5563, -7.0032, -4.6198, -6.0098, -4.3959, -6.7773,\n",
      "         -6.5881, -5.3570, -5.3487, -3.5594]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "texto = \"I love this movie!\"\n",
    "inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "outputs = modelo_base(**inputs)\n",
    "\n",
    "# Obtener los logits\n",
    "logits = outputs.logits\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f7d4d",
   "metadata": {},
   "source": [
    "Ahora queremos obtener cual es la clase que es más probable que se haya predicho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b118d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase predicha (índice): 18\n",
      "Clase predicha (texto): love\n"
     ]
    }
   ],
   "source": [
    "probabilidades = torch.softmax(logits, dim=1)\n",
    "\n",
    "# Obtener la clase con la probabilidad más alta\n",
    "clase_predicha_idx = np.argmax(probabilidades.detach().numpy())\n",
    "clase_predicha = modelo_base.config.id2label[clase_predicha_idx]\n",
    "\n",
    "print(\"Clase predicha (índice):\", clase_predicha_idx)\n",
    "print(\"Clase predicha (texto):\", clase_predicha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c1ca8",
   "metadata": {},
   "source": [
    "## Creación de la clase  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef29e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_base  = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3d7ac",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe78600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df['Text_processed'].tolist()\n",
    "labels = df['Emotion'].tolist()\n",
    "\n",
    "# Convertir las etiquetas a números\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# tokenizar inputs\n",
    "inputs = tokenizer.batch_encode_plus(\n",
    "    inputs,\n",
    "    padding='longest', \n",
    "    truncation=True, \n",
    "    max_length=512, \n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967f61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Crear conjunto de datos\n",
    "dataset = MyDataset(inputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4829c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d71399",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b4b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clases = len(le.classes_)\n",
    "model = MiModelo(modelo_base, num_clases)\n",
    "\n",
    "total_layers = len(list(model.modelo_base.parameters()))\n",
    "unfrozen_layers = total_layers - 5  # Descongelar las últimas dos capas\n",
    "\n",
    "for i, param in enumerate(model.modelo_base.parameters()):\n",
    "    if i >= unfrozen_layers:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba2b1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a660ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                            | 0/329 [00:00<?, ?it/s]/tmp/ipykernel_3456/2026608765.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:19<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss 620.9824441671371 val_loss 122.46926438808441 val_accuracy 0.32919254658385094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:19<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss 570.1838754415512 val_loss 118.5407452583313 val_accuracy 0.354924578527063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:19<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 train_loss 550.0390100479126 val_loss 113.64480245113373 val_accuracy 0.4179236912156167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:19<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 train_loss 539.8629347085953 val_loss 111.97594094276428 val_accuracy 0.42147293700088734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:20<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 train_loss 530.1934432983398 val_loss 110.24114847183228 val_accuracy 0.4347826086956522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 train_loss 524.7585369348526 val_loss 107.54873764514923 val_accuracy 0.4489795918367347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:20<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 train_loss 516.2173202037811 val_loss 108.01743257045746 val_accuracy 0.4436557231588288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:20<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 train_loss 512.0536415576935 val_loss 106.51385533809662 val_accuracy 0.45785270629991126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 train_loss 507.69284331798553 val_loss 105.61835300922394 val_accuracy 0.4551907719609583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 train_loss 504.6957237124443 val_loss 105.75500655174255 val_accuracy 0.46761313220940554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 train_loss 501.45151048898697 val_loss 104.86665201187134 val_accuracy 0.48181011535048807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 train_loss 499.6391575932503 val_loss 104.65752303600311 val_accuracy 0.4640638864241349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 train_loss 499.1371239423752 val_loss 105.54090189933777 val_accuracy 0.4640638864241349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 train_loss 498.63329553604126 val_loss 104.65792346000671 val_accuracy 0.4685004436557232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 train_loss 498.7876763343811 val_loss 104.18033480644226 val_accuracy 0.4631765749778172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 train_loss 496.65752547979355 val_loss 104.66779208183289 val_accuracy 0.46938775510204084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 train_loss 491.45998668670654 val_loss 104.66905498504639 val_accuracy 0.4658385093167702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 train_loss 487.34506273269653 val_loss 104.30871969461441 val_accuracy 0.47559893522626445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 train_loss 489.71748822927475 val_loss 103.7476282119751 val_accuracy 0.4764862466725821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 train_loss 489.0888127088547 val_loss 104.32177197933197 val_accuracy 0.4667258207630879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 train_loss 489.659565448761 val_loss 103.74917984008789 val_accuracy 0.4667258207630879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 train_loss 488.70677024126053 val_loss 104.05494844913483 val_accuracy 0.4640638864241349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 train_loss 483.9819061756134 val_loss 103.97201120853424 val_accuracy 0.46938775510204084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 train_loss 483.69343888759613 val_loss 103.37992715835571 val_accuracy 0.48358473824312337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 train_loss 479.51529264450073 val_loss 103.21562075614929 val_accuracy 0.47293700088731144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 train_loss 480.77704149484634 val_loss 103.56675708293915 val_accuracy 0.4658385093167702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 train_loss 479.9029411673546 val_loss 103.34983813762665 val_accuracy 0.46761313220940554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 train_loss 475.4361726641655 val_loss 103.54295414686203 val_accuracy 0.4782608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 train_loss 477.21923196315765 val_loss 102.55630683898926 val_accuracy 0.48358473824312337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 train_loss 478.4516541957855 val_loss 103.22437846660614 val_accuracy 0.4800354924578527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 train_loss 474.9860428571701 val_loss 102.73733872175217 val_accuracy 0.4764862466725821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 train_loss 477.4199720621109 val_loss 103.02322751283646 val_accuracy 0.4702750665483585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 train_loss 476.70430839061737 val_loss 103.41206932067871 val_accuracy 0.4782608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 train_loss 472.2021464109421 val_loss 103.47956693172455 val_accuracy 0.4658385093167702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 train_loss 471.2787758111954 val_loss 103.38180494308472 val_accuracy 0.47559893522626445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 train_loss 471.9738625884056 val_loss 103.72267043590546 val_accuracy 0.4649511978704525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 train_loss 471.2930969595909 val_loss 103.27859073877335 val_accuracy 0.46938775510204084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 train_loss 471.0619025826454 val_loss 103.97655296325684 val_accuracy 0.4658385093167702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 train_loss 467.9336362481117 val_loss 102.98578125238419 val_accuracy 0.4747116237799468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 train_loss 467.60608011484146 val_loss 103.28050863742828 val_accuracy 0.46938775510204084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:21<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 train_loss 466.53178119659424 val_loss 103.80378592014313 val_accuracy 0.4685004436557232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 249/329 [00:16<00:05, 15.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     26\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_loader))\n\u001b[1;32m     27\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 300\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop_epochs = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss/len(train_loader))\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "        val_accuracy = correct_predictions.double() / len(val_dataset)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "    print(f'epoch: {epoch} train_loss {train_loss} val_loss {val_loss} val_accuracy {val_accuracy}')\n",
    "\n",
    "    # Implement Early Stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        # Check early stopping condition\n",
    "        if epochs_no_improve == early_stop_epochs:\n",
    "            print('Early stopping!')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([acc.cpu() for acc in val_accuracies], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", inference_mode=False, r=16, lora_alpha=16, lora_dropout=0.1, bias=\"all\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30335c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b411bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MiModelo.push_to_hub(repo_id=\"RikoteMaster/Bert_peft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3191037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(mi_modelo, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d5924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
