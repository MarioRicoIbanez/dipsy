{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "      <td>on days when i feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "      <td>every time i imagine that someone i love or i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "      <td>when i had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "      <td>when i think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "      <td>at a gathering i found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>shame</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>shame</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>fear</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>guilt</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>fear</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7516 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Emotion                                               Text  \\\n",
       "0         joy  On days when I feel close to my partner and ot...   \n",
       "1        fear  Every time I imagine that someone I love or I ...   \n",
       "2       anger  When I had been obviously unjustly treated and...   \n",
       "3     sadness  When I think about the short time that we live...   \n",
       "4     disgust  At a gathering I found myself involuntarily si...   \n",
       "...       ...                                                ...   \n",
       "7511    shame  Two years back someone invited me to be the tu...   \n",
       "7512    shame  I had taken the responsibility to do something...   \n",
       "7513     fear  I was at home and I heard a loud sound of spit...   \n",
       "7514    guilt  I did not do the homework that the teacher had...   \n",
       "7515     fear  I had shouted at my younger brother and he was...   \n",
       "\n",
       "                                         Text_processed  \n",
       "0     on days when i feel close to my partner and ot...  \n",
       "1     every time i imagine that someone i love or i ...  \n",
       "2     when i had been obviously unjustly treated and...  \n",
       "3     when i think about the short time that we live...  \n",
       "4     at a gathering i found myself involuntarily si...  \n",
       "...                                                 ...  \n",
       "7511  two years back someone invited me to be the tu...  \n",
       "7512  i had taken the responsibility to do something...  \n",
       "7513  i was at home and i heard a loud sound of spit...  \n",
       "7514  i did not do the homework that the teacher had...  \n",
       "7515  i had shouted at my younger brother and he was...  \n",
       "\n",
       "[7516 rows x 3 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "import re\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "  df = pd.read_csv(file_path, names=['Emotion', 'Text', 'DNTKNOW']).drop(columns=['DNTKNOW']).dropna()\n",
    "  df['Text_processed'] = df.Text.apply(clean_text)\n",
    "  return df\n",
    "\n",
    "def clean_text(text):\n",
    "  # to lower case\n",
    "  text = text.lower()\n",
    "  # remove links\n",
    "  text = re.sub('https:\\/\\/\\S+', '', text)\n",
    "  # remove punctuation\n",
    "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "  # remove next line\n",
    "  text = re.sub(r'[^ \\w\\.]', '', text)\n",
    "  # remove words containing numbers\n",
    "  text = re.sub('\\w*\\d\\w*', '', text)\n",
    "\n",
    "  return text\n",
    "\n",
    "\n",
    "\n",
    "# Descarga y procesa el csv\n",
    "url = \"https://raw.githubusercontent.com/PoorvaRane/Emotion-Detector/master/ISEAR.csv\"\n",
    "output_file = \"ISEAR.csv\"\n",
    "destination_folder = \"data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(output_file, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "#if dir created do not create again\n",
    "if not os.path.exists('data'):\n",
    "   os.mkdir('data')\n",
    "\n",
    "shutil.move(output_file, f\"{destination_folder}/{output_file}\")\n",
    "\n",
    "# Carga y preprocesa el dataset\n",
    "df = load_and_preprocess_data(f'{destination_folder}/{output_file}')\n",
    "df['Emotion'] = df['Emotion'].replace('guit', 'guilt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "      <td>on days when i feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "      <td>every time i imagine that someone i love or i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "      <td>when i had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "      <td>when i think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "      <td>at a gathering i found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>shame</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>shame</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>fear</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>guilt</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>fear</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7516 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Emotion                                               Text  \\\n",
       "0         joy  On days when I feel close to my partner and ot...   \n",
       "1        fear  Every time I imagine that someone I love or I ...   \n",
       "2       anger  When I had been obviously unjustly treated and...   \n",
       "3     sadness  When I think about the short time that we live...   \n",
       "4     disgust  At a gathering I found myself involuntarily si...   \n",
       "...       ...                                                ...   \n",
       "7511    shame  Two years back someone invited me to be the tu...   \n",
       "7512    shame  I had taken the responsibility to do something...   \n",
       "7513     fear  I was at home and I heard a loud sound of spit...   \n",
       "7514    guilt  I did not do the homework that the teacher had...   \n",
       "7515     fear  I had shouted at my younger brother and he was...   \n",
       "\n",
       "                                         Text_processed  \n",
       "0     on days when i feel close to my partner and ot...  \n",
       "1     every time i imagine that someone i love or i ...  \n",
       "2     when i had been obviously unjustly treated and...  \n",
       "3     when i think about the short time that we live...  \n",
       "4     at a gathering i found myself involuntarily si...  \n",
       "...                                                 ...  \n",
       "7511  two years back someone invited me to be the tu...  \n",
       "7512  i had taken the responsibility to do something...  \n",
       "7513  i was at home and i heard a loud sound of spit...  \n",
       "7514  i did not do the homework that the teacher had...  \n",
       "7515  i had shouted at my younger brother and he was...  \n",
       "\n",
       "[7516 rows x 3 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_25 = pd.read_csv('data_isear/output_25.csv')\n",
    "df_50 = pd.read_csv('data_isear/output_50.csv')\n",
    "df_75 = pd.read_csv('data_isear/output_75.csv')\n",
    "df_25.drop(columns=['Sentence_Number'], inplace=True)\n",
    "df_50.drop(columns=['Sentence_Number'], inplace=True)\n",
    "df_75.drop(columns=['Sentence_Number'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While I was at the corner shop, a place I visit regularly, I had only a $50 note with me. I purchased essential goods worth about $3, but the shopkeeper made cynical remarks to others about people relying on him for cashing larger notes. anger\n",
      "     Emotion                                               Text  \\\n",
      "1880   anger  I was at the corner shop, which I patronise re...   \n",
      "\n",
      "                                         Text_processed  \n",
      "1880  i was at the corner shop which i patronise reg...  \n"
     ]
    }
   ],
   "source": [
    "print(df_50.iloc[0].Augmented_text, df_50.iloc[0].Sentiment)\n",
    "print(df[(df['Text'].str.contains('corner')) & (df['Emotion'] == 'anger')])\n",
    "start_50 = df[(df['Text'].str.contains('corner')) & (df['Emotion'] == 'anger')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every year during carnival, a profound sense of delight envelops me, accompanied by an overwhelming surge of exuberance. joy\n"
     ]
    }
   ],
   "source": [
    "print(df_75.iloc[2].Augmented_text, df_75.iloc[2].Sentiment)\n",
    "start_75 = df[(df['Text'].str.contains('Every year during carnival')) & (df['Emotion'] == 'joy')].index - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During moments of deep connection with my partner and dear friends, accompanied by a profound inner serenity and an intimate bond with those I hold dear, a sense of warmth and contentment envelops me. joy\n"
     ]
    }
   ],
   "source": [
    "print(df_25.iloc[0].Augmented_text, df_25.iloc[0].Sentiment)\n",
    "start_25 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Rename Sentiment for Emotion in df_50 and df_75\n",
    "\n",
    "df_25.rename(columns={'Sentiment': 'Emotion'}, inplace=True)\n",
    "df_50.rename(columns={'Sentiment': 'Emotion'}, inplace=True)\n",
    "df_75.rename(columns={'Sentiment': 'Emotion'}, inplace=True)\n",
    "df_25_original = df.iloc[start_25:start_50[0]].drop(columns=['Text'])\n",
    "df_50_original = df.iloc[start_50[0]:start_75[0]].drop(columns=['Text'])\n",
    "df_75_original = df.iloc[start_75[0]:start_75[0]+len(df_75)].drop(columns=['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea una mÃ¡scara para conocer cuales son las etiquetas que coinciden, llamdas Emotion\n",
    "df_25_original.reset_index(drop=True, inplace=True)\n",
    "mask_25 = df_25_original['Emotion']== df_25['Emotion']\n",
    "df_50_original.reset_index(drop=True, inplace=True)\n",
    "mask_50 = df_50_original['Emotion']== df_50['Emotion']\n",
    "df_75_original.reset_index(drop=True, inplace=True)\n",
    "mask_75 = df_75_original['Emotion']== df_75['Emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "fear       True\n",
      "joy        True\n",
      "anger      True\n",
      "sadness    True\n",
      "guilt      True\n",
      "disgust    True\n",
      "shame      True\n",
      "Name: count, dtype: bool\n",
      "Emotion\n",
      "anger      True\n",
      "guilt      True\n",
      "joy        True\n",
      "fear       True\n",
      "disgust    True\n",
      "shame      True\n",
      "sadness    True\n",
      "Name: count, dtype: bool\n",
      "Emotion\n",
      "joy        True\n",
      "shame      True\n",
      "anger      True\n",
      "fear       True\n",
      "sadness    True\n",
      "disgust    True\n",
      "guilt      True\n",
      "Name: count, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df_25_original[mask_25].Emotion.value_counts()==df_25.Emotion.value_counts())\n",
    "print(df_50_original[mask_50].Emotion.value_counts()==df_50.Emotion.value_counts())\n",
    "print(df_75_original[mask_75].Emotion.value_counts()==df_75.Emotion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'sadness', 'disgust', 'shame', 'guilt', 'joy', 'fear'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a list with the tags\n",
    "tags = df_50_original[mask_50].Emotion.unique()\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a mask with the rows that contains a tag in the Augmented_text\n",
    "mask_25 = df_25.Augmented_text.str.contains('|'.join(tags))\n",
    "mask_50 = df_50.Augmented_text.str.contains('|'.join(tags))\n",
    "mask_75 = df_75.Augmented_text.str.contains('|'.join(tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "guilt      60\n",
      "fear       59\n",
      "shame      48\n",
      "anger      39\n",
      "sadness    29\n",
      "disgust    23\n",
      "joy        16\n",
      "Name: count, dtype: int64\n",
      "Emotion\n",
      "fear       66\n",
      "guilt      64\n",
      "anger      41\n",
      "shame      39\n",
      "sadness    36\n",
      "joy        27\n",
      "disgust    25\n",
      "Name: count, dtype: int64\n",
      "Emotion\n",
      "guilt      69\n",
      "fear       51\n",
      "anger      48\n",
      "shame      47\n",
      "sadness    46\n",
      "disgust    36\n",
      "joy        28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_25[mask_25].Emotion.value_counts())\n",
    "print(df_50[mask_50].Emotion.value_counts())\n",
    "print(df_75[mask_75].Emotion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the rows that contains a tag in the Augmented_text\n",
    "df_25 = df_25[~mask_25]\n",
    "df_50 = df_50[~mask_50]\n",
    "df_75 = df_75[~mask_75]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column called augmented in df_50 df_75 and set default to true, and set to false in df_50_original and df_75_original\n",
    "df_25['Augmented'] = True\n",
    "df_50['Augmented'] = True\n",
    "df_75['Augmented'] = True\n",
    "df_25_original['Augmented'] = False\n",
    "df_50_original['Augmented'] = False\n",
    "df_75_original['Augmented'] = False\n",
    "\n",
    "#Now rename the columns in df_50 and df_75 \n",
    "df_25.rename(columns={'Augmented_text': 'Text_processed'}, inplace=True)\n",
    "df_50.rename(columns={'Augmented_text': 'Text_processed'}, inplace=True)\n",
    "df_75.rename(columns={'Augmented_text': 'Text_processed'}, inplace=True)\n",
    "\n",
    "#Now apply clean_text to df_50 and df_75\n",
    "df_25['Text_processed'] = df_25.Text_processed.apply(clean_text)\n",
    "df_50['Text_processed'] = df_50.Text_processed.apply(clean_text)\n",
    "df_75['Text_processed'] = df_75.Text_processed.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['Text'], inplace=True)\n",
    "df['Augmented'] = False\n",
    "#Concat df_50 df_75 with df\n",
    "df = pd.concat([df, df_25, df_50, df_75], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text_processed</th>\n",
       "      <th>Augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>on days when i feel close to my partner and ot...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>every time i imagine that someone i love or i ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>when i had been obviously unjustly treated and...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>when i think about the short time that we live...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>at a gathering i found myself involuntarily si...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>disgust</td>\n",
       "      <td>reading a newspaper article recounting the tra...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12253</th>\n",
       "      <td>shame</td>\n",
       "      <td>after engaging in a casual encounter with a gi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12254</th>\n",
       "      <td>anger</td>\n",
       "      <td>while working on a project with a coworker i b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>sadness</td>\n",
       "      <td>our family recently placed a young chick outdo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12258</th>\n",
       "      <td>joy</td>\n",
       "      <td>at a dear friends  birthday celebration everyt...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12255 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Emotion                                     Text_processed  Augmented\n",
       "0          joy  on days when i feel close to my partner and ot...      False\n",
       "1         fear  every time i imagine that someone i love or i ...      False\n",
       "2        anger  when i had been obviously unjustly treated and...      False\n",
       "3      sadness  when i think about the short time that we live...      False\n",
       "4      disgust  at a gathering i found myself involuntarily si...      False\n",
       "...        ...                                                ...        ...\n",
       "12252  disgust  reading a newspaper article recounting the tra...       True\n",
       "12253    shame  after engaging in a casual encounter with a gi...       True\n",
       "12254    anger  while working on a project with a coworker i b...       True\n",
       "12255  sadness  our family recently placed a young chick outdo...       True\n",
       "12258      joy  at a dear friends  birthday celebration everyt...       True\n",
       "\n",
       "[12255 rows x 3 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the rows that contains no response in Text_processed, but \n",
    "df = df[df['Text_processed'] != 'no response provided']\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_isear/ISEAR_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Emotion', 'Text_processed', 'Augmented'],\n",
       "        num_rows: 10751\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Emotion', 'Text_processed', 'Augmented'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Emotion', 'Text_processed', 'Augmented'],\n",
       "        num_rows: 752\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "#Separate between augmented and original \n",
    "df_augmented = df[df['Augmented'] == True]\n",
    "df_original = df[df['Augmented'] == False]\n",
    "#Create df_train,df_val,df_test\n",
    "df_train,df_val = train_test_split(df_original, test_size=0.2, random_state=42)\n",
    "df_val,df_test = train_test_split(df_val, test_size=0.5, random_state=42)\n",
    "#Concatenate df_augmented with df_train\n",
    "df_train = pd.concat([df_train, df_augmented], ignore_index=True)\n",
    "\n",
    "#now Create a DatasetDict with the three datasets\n",
    "dataset_dict = DatasetDict({'train': Dataset.from_pandas(df_train),\n",
    "                            'validation': Dataset.from_pandas(df_val),\n",
    "                            'test': Dataset.from_pandas(df_test)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_dict['validation'] = dataset_dict['validation'].remove_columns(['__index_level_0__'])\n",
    "dataset_dict['test'] = dataset_dict['test'].remove_columns(['__index_level_0__'])\n",
    "\n",
    "\n",
    "#push to huggingface datasets\n",
    "dataset_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 735.64ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.57s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 456.85ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 491.54ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict.push_to_hub('isear_augmented')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwhelming, remorse, Note"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
