{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2075c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: accelerate 0.18.0\n",
      "Uninstalling accelerate-0.18.0:\n",
      "  Successfully uninstalled accelerate-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: appdirs 1.4.4\n",
      "Uninstalling appdirs-1.4.4:\n",
      "  Successfully uninstalled appdirs-1.4.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: bitsandbytes 0.37.2\n",
      "Uninstalling bitsandbytes-0.37.2:\n",
      "  Successfully uninstalled bitsandbytes-0.37.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: fire 0.5.0\n",
      "Uninstalling fire-0.5.0:\n",
      "  Successfully uninstalled fire-0.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping sentencepiece as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping gradio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch 2.0.1\n",
      "Uninstalling torch-2.0.1:\n",
      "  Successfully uninstalled torch-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y accelerate\n",
    "!pip uninstall -y appdirs \n",
    "!pip uninstall -y bitsandbytes  \n",
    "!pip uninstall -y datasets\n",
    "!pip uninstall -y fire\n",
    "!pip uninstall -y peft  \n",
    "!pip uninstall -y transformers  \n",
    "!pip uninstall -y sentencepiece \n",
    "!pip uninstall -y gradio\n",
    "!pip uninstall -y torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b5c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting accelerate==0.18.0\n",
      "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.18.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.18.0) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate==0.18.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate==0.18.0) (6.0)\n",
      "Collecting torch>=1.4.0 (from accelerate==0.18.0)\n",
      "  Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (4.6.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate==0.18.0) (68.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate==0.18.0) (0.40.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.18.0) (3.26.4)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.18.0) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.4.0->accelerate==0.18.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.4.0->accelerate==0.18.0) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch, accelerate\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.15.1 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.18.0 torch-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting appdirs==1.4.4\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: appdirs\n",
      "Successfully installed appdirs-1.4.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting bitsandbytes==0.37.2\n",
      "  Downloading bitsandbytes-0.37.2-py3-none-any.whl (84.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.37.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting datasets==2.10.1\n",
      "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (0.15.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.10.1) (6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.10.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.10.1) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.10.1) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.10.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.10.1) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.10.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: datasets\n",
      "Successfully installed datasets-2.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting fire==0.5.0\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire==0.5.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire==0.5.0) (2.3.0)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=a0a450ef502b0f91ba0817addc0b97f63a9b12b3c758611fd1411643c91c6103\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8uk2daaz/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
      "Successfully built fire\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: fire\n",
      "Successfully installed fire-0.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/huggingface/peft.git@86f4e45dccf873dd04348b08dbadd30d50171ccc\n",
      "  Cloning https://github.com/huggingface/peft.git (to revision 86f4e45dccf873dd04348b08dbadd30d50171ccc) to /tmp/pip-req-build-zfmea8q6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-zfmea8q6\n",
      "  Running command git rev-parse -q --verify 'sha^86f4e45dccf873dd04348b08dbadd30d50171ccc'\n",
      "  Running command git fetch -q https://github.com/huggingface/peft.git 86f4e45dccf873dd04348b08dbadd30d50171ccc\n",
      "  Running command git checkout -q 86f4e45dccf873dd04348b08dbadd30d50171ccc\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 86f4e45dccf873dd04348b08dbadd30d50171ccc\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from peft==0.3.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from peft==0.3.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from peft==0.3.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from peft==0.3.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from peft==0.3.0.dev0) (2.0.1)\n",
      "Collecting transformers (from peft==0.3.0.dev0)\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (from peft==0.3.0.dev0) (0.18.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.3.0.dev0) (68.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.3.0.dev0) (0.40.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.3.0.dev0) (3.26.4)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.3.0.dev0) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.3.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.3.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.3.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.3.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.3.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->peft==0.3.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.3.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.13.0->peft==0.3.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.3.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.3.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.13.0->peft==0.3.0.dev0) (1.3.0)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=41496 sha256=883d4c006285ec2f5c1e13873b761b4114a8cae99e9afe6511ca8f0135e2c268\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g83atzgf/wheels/1f/56/40/9b35b269ba37a156279278437496e827b5da3b0056167d3af8\n",
      "Successfully built peft\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: transformers, peft\n",
      "Successfully installed peft-0.3.0.dev0 transformers-4.30.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/huggingface/transformers.git@c612628045822f909020f7eb6784c79700813eda\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision c612628045822f909020f7eb6784c79700813eda) to /tmp/pip-req-build-vam_xzy6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-vam_xzy6\n",
      "  Running command git rev-parse -q --verify 'sha^c612628045822f909020f7eb6784c79700813eda'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers.git c612628045822f909020f7eb6784c79700813eda\n",
      "  Running command git checkout -q c612628045822f909020f7eb6784c79700813eda\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit c612628045822f909020f7eb6784c79700813eda\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.28.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.28.0.dev0) (2023.5.7)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=6858427 sha256=a42be34d6c9fc4a84abdf0f9a1befc7e2a9ec6830eb0ddf2534891e0a7e9a552\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-oqfivjf3/wheels/bc/39/e2/1c9515414422cefa80cf6fead01704cdf091c928cf99eaf8c5\n",
      "Successfully built transformers\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "Successfully installed transformers-4.28.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch 2.0.1\n",
      "Uninstalling torch-2.0.1:\n",
      "  Successfully uninstalled torch-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch==2.0\n",
      "  Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (4.6.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/dist-packages (from torch==2.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0) (68.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0) (0.40.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch==2.0) (3.26.4)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0->torch==2.0) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch==2.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch==2.0) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch\n",
      "Successfully installed torch-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sentencepiece==0.1.97\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboardX==2.6 in /usr/local/lib/python3.8/dist-packages (2.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6) (1.24.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6) (23.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6) (3.20.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting gradio==3.23.0\n",
      "  Downloading gradio-3.23.0-py3-none-any.whl (15.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiofiles in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (3.8.4)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (5.0.1)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.98.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (2023.6.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.15.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (3.7.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (1.24.4)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (3.9.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (2.0.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (9.5.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (1.10.9)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.0.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (2.31.0)\n",
      "Requirement already satisfied: semantic-version in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (4.6.3)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.8/dist-packages (from gradio==3.23.0) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio==3.23.0) (4.17.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio==3.23.0) (0.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->gradio==3.23.0) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->gradio==3.23.0) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->gradio==3.23.0) (23.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio==3.23.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio==3.23.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio==3.23.0) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio==3.23.0) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.8/dist-packages (from fastapi->gradio==3.23.0) (0.27.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio==3.23.0) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from httpx->gradio==3.23.0) (0.17.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.8/dist-packages (from httpx->gradio==3.23.0) (3.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx->gradio==3.23.0) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.23.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.23.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.23.0) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.23.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.23.0) (3.1.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio==3.23.0) (5.12.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio==3.23.0) (2.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio==3.23.0) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio==3.23.0) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.8/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0) (3.7.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib->gradio==3.23.0) (3.15.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0) (0.19.3)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.8/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas->gradio==3.23.0) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.8/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0) (1.1.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: gradio\n",
      "Successfully installed gradio-3.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -U pip\n",
    "!pip install accelerate==0.18.0  \n",
    "!pip install appdirs==1.4.4  \n",
    "!pip install bitsandbytes==0.37.2  \n",
    "!pip install datasets==2.10.1 \n",
    "!pip install fire==0.5.0 \n",
    "!pip install git+https://github.com/huggingface/peft.git@86f4e45dccf873dd04348b08dbadd30d50171ccc  \n",
    "!pip install git+https://github.com/huggingface/transformers.git@c612628045822f909020f7eb6784c79700813eda  \n",
    "!pip uninstall -y torch \n",
    "!pip install torch==2.0\n",
    "!pip install sentencepiece==0.1.97  \n",
    "!pip install tensorboardX==2.6  \n",
    "!pip install gradio==3.23.0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9368f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 120\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda120_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/compat/lib'), PosixPath('/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib'), PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/lib/python3.8/dist-packages/torch/lib:/usr/local/lib/python3.8/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"/tmp/vscode-ssh-auth-e1832c8d-441a-4167-9cb4-86c7c8c18093.sock\",\"/root/.gnupg/S.gpg-agent\"]')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import textwrap\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    " \n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    ")\n",
    " \n",
    "import fire\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    " \n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(10, 7)})\n",
    "sns.set(rc={'figure.dpi':100})\n",
    "sns.set(style='white', palette='muted', font_scale=1.2)\n",
    " \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12a65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xQ89cpZCnafsW5T3G3ZQWvR7q682t2BN\n",
      "To: /home/mriciba/Projects/dipsy/llama/bitcoin-sentiment-tweets.csv\n",
      "100%|████████████████████████████████████████| 242k/242k [00:00<00:00, 2.78MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1xQ89cpZCnafsW5T3G3ZQWvR7q682t2BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1bf1826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Mar 23 00:40:40 +0000 2018</td>\n",
       "      <td>@p0nd3ea Bitcoin wasn't built to live on excha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Mar 23 00:40:40 +0000 2018</td>\n",
       "      <td>@historyinflicks Buddy if I had whatever serie...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Mar 23 00:40:42 +0000 2018</td>\n",
       "      <td>@eatBCH @Bitcoin @signalapp @myWickr @Samsung ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Mar 23 00:41:04 +0000 2018</td>\n",
       "      <td>@aantonop Even if Bitcoin crash tomorrow morni...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Mar 23 00:41:07 +0000 2018</td>\n",
       "      <td>I am experimenting whether I can live only wit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  \\\n",
       "0  Fri Mar 23 00:40:40 +0000 2018   \n",
       "1  Fri Mar 23 00:40:40 +0000 2018   \n",
       "2  Fri Mar 23 00:40:42 +0000 2018   \n",
       "3  Fri Mar 23 00:41:04 +0000 2018   \n",
       "4  Fri Mar 23 00:41:07 +0000 2018   \n",
       "\n",
       "                                               tweet  sentiment  \n",
       "0  @p0nd3ea Bitcoin wasn't built to live on excha...        1.0  \n",
       "1  @historyinflicks Buddy if I had whatever serie...        1.0  \n",
       "2  @eatBCH @Bitcoin @signalapp @myWickr @Samsung ...        0.0  \n",
       "3  @aantonop Even if Bitcoin crash tomorrow morni...        0.0  \n",
       "4  I am experimenting whether I can live only wit...        1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bitcoin-sentiment-tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f66d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       " 0.0    860\n",
       " 1.0    779\n",
       "-1.0    258\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b3e986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sentiment.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7815ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Detect the sentiment of the tweet.',\n",
       " 'input': \"@p0nd3ea Bitcoin wasn't built to live on exchanges.\",\n",
       " 'output': 'Positive'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment_score_to_name(score: float):\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score < 0:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    " \n",
    "dataset_data = [\n",
    "    {\n",
    "        \"instruction\": \"Detect the sentiment of the tweet.\",\n",
    "        \"input\": row_dict[\"tweet\"],\n",
    "        \"output\": sentiment_score_to_name(row_dict[\"sentiment\"])\n",
    "    }\n",
    "    for row_dict in df.to_dict(orient=\"records\")\n",
    "]\n",
    " \n",
    "dataset_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd194f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"alpaca-bitcoin-sentiment-dataset.json\", \"w\") as f:\n",
    "   json.dump(dataset_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5748268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  3 17:04:49 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN V      Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 58%   68C    P8    35W / 250W |      4MiB / 12288MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1206e6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e6d03966b0496ea1b74fc839f4c215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL = \"decapoda-research/llama-7b-hf\"\n",
    " \n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    "    \n",
    ")\n",
    " \n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    " \n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f628a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  3 17:05:00 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN V      Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 56%   66C    P2    44W / 250W |   7652MiB / 12288MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecac0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-9029cdee8be5596d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ffc21a2bb44a24a0864e01499e527b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac0fa9b819a4557bf54be112dfd0e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-9029cdee8be5596d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b2348ebf994cd19aad87b320c80fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 1897\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"alpaca-bitcoin-sentiment-dataset.json\")\n",
    "data[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdeae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  # noqa: E501\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    " \n",
    " \n",
    "def tokenize(prompt, add_eos_token=True):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < CUTOFF_LEN\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    " \n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    " \n",
    "    return result\n",
    " \n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf7876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF_LEN = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c0a3f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1697 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=200, shuffle=True, seed=42\n",
    ")\n",
    "train_data = (\n",
    "    train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
    ")\n",
    "val_data = (\n",
    "    train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8538bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    " \n",
    "BATCH_SIZE = 128\n",
    "MICRO_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_STEPS = 600\n",
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "418431ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd94da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_steps=100,\n",
    "    max_steps=TRAIN_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa60da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d00613bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping apex as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de001758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 4:49:11, Epoch 45/47]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.097600</td>\n",
       "      <td>1.845494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.093700</td>\n",
       "      <td>1.593464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.977400</td>\n",
       "      <td>1.646798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.364600</td>\n",
       "      <td>1.648532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.077500</td>\n",
       "      <td>1.649025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.141100</td>\n",
       "      <td>1.648372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.829500</td>\n",
       "      <td>1.648804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.957000</td>\n",
       "      <td>1.648744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.231100</td>\n",
       "      <td>1.648833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.weight', 'base_model.model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.model.layers.0.self_attn.v_proj.weight', 'base_model.model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.model.layers.0.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.model.layers.0.mlp.down_proj.weight', 'base_model.model.model.layers.0.mlp.up_proj.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.weight', 'base_model.model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.model.layers.1.self_attn.v_proj.weight', 'base_model.model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.model.layers.1.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.model.layers.1.mlp.down_proj.weight', 'base_model.model.model.layers.1.mlp.up_proj.weight', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.weight', 'base_model.model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.model.layers.2.self_attn.v_proj.weight', 'base_model.model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.model.layers.2.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.model.layers.2.mlp.down_proj.weight', 'base_model.model.model.layers.2.mlp.up_proj.weight', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.weight', 'base_model.model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.model.layers.3.self_attn.v_proj.weight', 'base_model.model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.model.layers.3.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.model.layers.3.mlp.down_proj.weight', 'base_model.model.model.layers.3.mlp.up_proj.weight', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.weight', 'base_model.model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.model.layers.4.self_attn.v_proj.weight', 'base_model.model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.model.layers.4.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.model.layers.4.mlp.down_proj.weight', 'base_model.model.model.layers.4.mlp.up_proj.weight', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.weight', 'base_model.model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.model.layers.5.self_attn.v_proj.weight', 'base_model.model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.model.layers.5.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.model.layers.5.mlp.down_proj.weight', 'base_model.model.model.layers.5.mlp.up_proj.weight', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.weight', 'base_model.model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.model.layers.6.self_attn.v_proj.weight', 'base_model.model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.model.layers.6.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.model.layers.6.mlp.down_proj.weight', 'base_model.model.model.layers.6.mlp.up_proj.weight', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.weight', 'base_model.model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.model.layers.7.self_attn.v_proj.weight', 'base_model.model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.model.layers.7.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.model.layers.7.mlp.down_proj.weight', 'base_model.model.model.layers.7.mlp.up_proj.weight', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.weight', 'base_model.model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.model.layers.8.self_attn.v_proj.weight', 'base_model.model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.model.layers.8.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.model.layers.8.mlp.down_proj.weight', 'base_model.model.model.layers.8.mlp.up_proj.weight', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.weight', 'base_model.model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.model.layers.9.self_attn.v_proj.weight', 'base_model.model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.model.layers.9.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.model.layers.9.mlp.down_proj.weight', 'base_model.model.model.layers.9.mlp.up_proj.weight', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.weight', 'base_model.model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.model.layers.10.self_attn.v_proj.weight', 'base_model.model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.model.layers.10.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.model.layers.10.mlp.down_proj.weight', 'base_model.model.model.layers.10.mlp.up_proj.weight', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.weight', 'base_model.model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.model.layers.11.self_attn.v_proj.weight', 'base_model.model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.model.layers.11.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.model.layers.11.mlp.down_proj.weight', 'base_model.model.model.layers.11.mlp.up_proj.weight', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.weight', 'base_model.model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.model.layers.12.self_attn.v_proj.weight', 'base_model.model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.model.layers.12.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.model.layers.12.mlp.down_proj.weight', 'base_model.model.model.layers.12.mlp.up_proj.weight', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.weight', 'base_model.model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.model.layers.13.self_attn.v_proj.weight', 'base_model.model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.model.layers.13.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.model.layers.13.mlp.down_proj.weight', 'base_model.model.model.layers.13.mlp.up_proj.weight', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.weight', 'base_model.model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.model.layers.14.self_attn.v_proj.weight', 'base_model.model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.model.layers.14.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.model.layers.14.mlp.down_proj.weight', 'base_model.model.model.layers.14.mlp.up_proj.weight', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.weight', 'base_model.model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.model.layers.15.self_attn.v_proj.weight', 'base_model.model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.model.layers.15.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.model.layers.15.mlp.down_proj.weight', 'base_model.model.model.layers.15.mlp.up_proj.weight', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.weight', 'base_model.model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.model.layers.16.self_attn.v_proj.weight', 'base_model.model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.model.layers.16.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.model.layers.16.mlp.down_proj.weight', 'base_model.model.model.layers.16.mlp.up_proj.weight', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.weight', 'base_model.model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.model.layers.17.self_attn.v_proj.weight', 'base_model.model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.model.layers.17.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.model.layers.17.mlp.down_proj.weight', 'base_model.model.model.layers.17.mlp.up_proj.weight', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.weight', 'base_model.model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.model.layers.18.self_attn.v_proj.weight', 'base_model.model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.model.layers.18.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.model.layers.18.mlp.down_proj.weight', 'base_model.model.model.layers.18.mlp.up_proj.weight', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.weight', 'base_model.model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.model.layers.19.self_attn.v_proj.weight', 'base_model.model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.model.layers.19.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.model.layers.19.mlp.down_proj.weight', 'base_model.model.model.layers.19.mlp.up_proj.weight', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.weight', 'base_model.model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.model.layers.20.self_attn.v_proj.weight', 'base_model.model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.model.layers.20.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.model.layers.20.mlp.down_proj.weight', 'base_model.model.model.layers.20.mlp.up_proj.weight', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.weight', 'base_model.model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.model.layers.21.self_attn.v_proj.weight', 'base_model.model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.model.layers.21.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.model.layers.21.mlp.down_proj.weight', 'base_model.model.model.layers.21.mlp.up_proj.weight', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.weight', 'base_model.model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.model.layers.22.self_attn.v_proj.weight', 'base_model.model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.model.layers.22.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.model.layers.22.mlp.down_proj.weight', 'base_model.model.model.layers.22.mlp.up_proj.weight', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.weight', 'base_model.model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.model.layers.23.self_attn.v_proj.weight', 'base_model.model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.model.layers.23.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.model.layers.23.mlp.down_proj.weight', 'base_model.model.model.layers.23.mlp.up_proj.weight', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.weight', 'base_model.model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.model.layers.24.self_attn.v_proj.weight', 'base_model.model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.model.layers.24.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.model.layers.24.mlp.down_proj.weight', 'base_model.model.model.layers.24.mlp.up_proj.weight', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.weight', 'base_model.model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.model.layers.25.self_attn.v_proj.weight', 'base_model.model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.model.layers.25.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.model.layers.25.mlp.down_proj.weight', 'base_model.model.model.layers.25.mlp.up_proj.weight', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.weight', 'base_model.model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.model.layers.26.self_attn.v_proj.weight', 'base_model.model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.model.layers.26.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.model.layers.26.mlp.down_proj.weight', 'base_model.model.model.layers.26.mlp.up_proj.weight', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.weight', 'base_model.model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.model.layers.27.self_attn.v_proj.weight', 'base_model.model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.model.layers.27.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.model.layers.27.mlp.down_proj.weight', 'base_model.model.model.layers.27.mlp.up_proj.weight', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.weight', 'base_model.model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.model.layers.28.self_attn.v_proj.weight', 'base_model.model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.model.layers.28.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.model.layers.28.mlp.down_proj.weight', 'base_model.model.model.layers.28.mlp.up_proj.weight', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.weight', 'base_model.model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.model.layers.29.self_attn.v_proj.weight', 'base_model.model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.model.layers.29.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.model.layers.29.mlp.down_proj.weight', 'base_model.model.model.layers.29.mlp.up_proj.weight', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.weight', 'base_model.model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.model.layers.30.self_attn.v_proj.weight', 'base_model.model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.model.layers.30.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.model.layers.30.mlp.down_proj.weight', 'base_model.model.model.layers.30.mlp.up_proj.weight', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.weight', 'base_model.model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.model.layers.31.self_attn.v_proj.weight', 'base_model.model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.model.layers.31.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.model.layers.31.mlp.down_proj.weight', 'base_model.model.model.layers.31.mlp.up_proj.weight', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.0.weight'].\n"
     ]
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=training_arguments,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "model.config.use_cache = False\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(\n",
    "        self, old_state_dict()\n",
    "    )\n",
    ").__get__(model, type(model))\n",
    " \n",
    "model = torch.compile(model)\n",
    " \n",
    "trainer.train()\n",
    "model.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741376bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  3 21:54:46 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN V      Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 61%   79C    P2    58W / 250W |   9622MiB / 12288MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e20e518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aa2389adbd4215a4e5b1fecb5ba0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba8804455fe4a9aa8b4ff1f1cbe3cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/RikoteMaster/llama_try/commit/9dc7f8e7afe972f822aceb8b243c362d8afcddd1', commit_message='Upload model', commit_description='', oid='9dc7f8e7afe972f822aceb8b243c362d8afcddd1', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(repo_id=\"llama_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5bbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tloen/alpaca-lora.git\n",
    "%cd alpaca-lora\n",
    "!git checkout a48d947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367119de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate.py \\\n",
    "    --load_8bit \\\n",
    "    --base_model 'decapoda-research/llama-7b-hf' \\\n",
    "    --lora_weights 'RikoteMaster/llama_try' \\\n",
    "    --share_gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0fa4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
