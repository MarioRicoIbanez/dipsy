{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43221f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-07 08:44:00,449] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from numpy import save, asarray\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3f1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"RikoteMaster/translation_4_llama2_with_end_token\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"llama-2-7b-translator\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 3\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = True\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 64\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 3e-6\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine)\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 25\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52094f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 541/541 [00:00<00:00, 5.31MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading data files:   0%|                                                                                                              | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading data:   0%|                                                                                                              | 0.00/6.34M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 6.34M/6.34M [00:01<00:00, 5.12MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1113.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating train split:   0%|                                                                                                  | 0/118964 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split:  34%|███████████████████████████▌                                                      | 40000/118964 [00:00<00:00, 302772.80 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████| 118964/118964 [00:00<00:00, 364488.70 examples/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading checkpoint shards:   0%|                                                                                                           | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards:  50%|█████████████████████████████████████████████████▌                                                 | 1/2 [00:01<00:01,  1.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.32s/it]\u001b[A\u001b[A\n",
      "/usr/local/lib/python3.8/dist-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Map:   0%|                                                                                                                     | 0/118964 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   1%|▊                                                                                                       | 1000/118964 [00:00<00:20, 5657.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   2%|█▋                                                                                                      | 2000/118964 [00:00<00:16, 7179.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   3%|██▌                                                                                                     | 3000/118964 [00:00<00:14, 7775.48 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   3%|███▍                                                                                                    | 4000/118964 [00:00<00:13, 8215.24 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   4%|████▎                                                                                                   | 5000/118964 [00:00<00:13, 8401.23 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   5%|█████▏                                                                                                  | 6000/118964 [00:00<00:13, 8507.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   6%|██████                                                                                                  | 7000/118964 [00:00<00:12, 8625.44 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   7%|██████▉                                                                                                 | 8000/118964 [00:00<00:13, 8462.75 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   8%|███████▊                                                                                                | 9000/118964 [00:01<00:13, 8215.13 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   8%|████████▋                                                                                              | 10000/118964 [00:01<00:13, 8029.71 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   9%|█████████▌                                                                                             | 11000/118964 [00:01<00:13, 8092.31 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  10%|██████████▍                                                                                            | 12000/118964 [00:01<00:13, 8136.15 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  11%|███████████▎                                                                                           | 13000/118964 [00:01<00:13, 8126.20 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  12%|████████████                                                                                           | 14000/118964 [00:01<00:13, 8019.07 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  13%|████████████▉                                                                                          | 15000/118964 [00:01<00:13, 7890.27 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  13%|█████████████▊                                                                                         | 16000/118964 [00:01<00:13, 7901.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  14%|██████████████▋                                                                                        | 17000/118964 [00:02<00:12, 7968.53 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  15%|███████████████▌                                                                                       | 18000/118964 [00:02<00:12, 8028.87 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  16%|████████████████▍                                                                                      | 19000/118964 [00:02<00:12, 8180.88 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  17%|█████████████████▎                                                                                     | 20000/118964 [00:02<00:12, 8245.89 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  18%|██████████████████▏                                                                                    | 21000/118964 [00:02<00:11, 8251.69 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  18%|███████████████████                                                                                    | 22000/118964 [00:02<00:11, 8284.73 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  19%|███████████████████▉                                                                                   | 23000/118964 [00:02<00:11, 8286.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  20%|████████████████████▊                                                                                  | 24000/118964 [00:02<00:11, 8250.23 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  21%|█████████████████████▋                                                                                 | 25000/118964 [00:03<00:11, 8111.24 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  22%|██████████████████████▌                                                                                | 26000/118964 [00:03<00:11, 8194.57 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  23%|███████████████████████▍                                                                               | 27000/118964 [00:03<00:11, 8213.13 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  24%|████████████████████████▏                                                                              | 28000/118964 [00:03<00:11, 8181.91 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  24%|█████████████████████████                                                                              | 29000/118964 [00:03<00:10, 8230.65 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  25%|█████████████████████████▉                                                                             | 30000/118964 [00:03<00:10, 8217.02 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  26%|██████████████████████████▊                                                                            | 31000/118964 [00:03<00:10, 8293.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  27%|███████████████████████████▋                                                                           | 32000/118964 [00:03<00:10, 8303.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  28%|████████████████████████████▌                                                                          | 33000/118964 [00:04<00:10, 8240.13 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  29%|█████████████████████████████▍                                                                         | 34000/118964 [00:04<00:10, 8288.77 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  29%|██████████████████████████████▎                                                                        | 35000/118964 [00:04<00:10, 8337.61 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  30%|███████████████████████████████▏                                                                       | 36000/118964 [00:04<00:10, 8257.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  31%|████████████████████████████████                                                                       | 37000/118964 [00:04<00:09, 8282.26 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  32%|████████████████████████████████▉                                                                      | 38000/118964 [00:04<00:09, 8301.60 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  33%|█████████████████████████████████▊                                                                     | 39000/118964 [00:04<00:09, 8319.24 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  34%|██████████████████████████████████▋                                                                    | 40000/118964 [00:04<00:09, 8358.98 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  34%|███████████████████████████████████▍                                                                   | 41000/118964 [00:05<00:09, 8418.48 examples/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  35%|████████████████████████████████████▎                                                                  | 42000/118964 [00:05<00:09, 8387.99 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  36%|█████████████████████████████████████▏                                                                 | 43000/118964 [00:05<00:08, 8446.50 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  37%|██████████████████████████████████████                                                                 | 44000/118964 [00:05<00:08, 8436.02 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  38%|██████████████████████████████████████▉                                                                | 45000/118964 [00:05<00:08, 8338.03 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  39%|███████████████████████████████████████▊                                                               | 46000/118964 [00:05<00:08, 8365.90 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  40%|████████████████████████████████████████▋                                                              | 47000/118964 [00:05<00:08, 8375.42 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  40%|█████████████████████████████████████████▌                                                             | 48000/118964 [00:06<00:12, 5532.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  41%|██████████████████████████████████████████▍                                                            | 49000/118964 [00:06<00:11, 6181.79 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  42%|███████████████████████████████████████████▎                                                           | 50000/118964 [00:06<00:10, 6656.63 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  43%|████████████████████████████████████████████▏                                                          | 51000/118964 [00:06<00:09, 7046.03 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  44%|█████████████████████████████████████████████                                                          | 52000/118964 [00:06<00:09, 7430.26 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  45%|█████████████████████████████████████████████▉                                                         | 53000/118964 [00:06<00:08, 7695.22 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  45%|██████████████████████████████████████████████▊                                                        | 54000/118964 [00:06<00:08, 7786.57 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  46%|███████████████████████████████████████████████▌                                                       | 55000/118964 [00:06<00:08, 7990.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  47%|████████████████████████████████████████████████▍                                                      | 56000/118964 [00:07<00:07, 8121.36 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  48%|█████████████████████████████████████████████████▎                                                     | 57000/118964 [00:07<00:07, 8152.17 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  49%|██████████████████████████████████████████████████▏                                                    | 58000/118964 [00:07<00:07, 8260.81 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  50%|███████████████████████████████████████████████████                                                    | 59000/118964 [00:07<00:07, 8294.13 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  50%|███████████████████████████████████████████████████▉                                                   | 60000/118964 [00:07<00:07, 8212.02 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  51%|████████████████████████████████████████████████████▊                                                  | 61000/118964 [00:07<00:06, 8303.30 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  52%|█████████████████████████████████████████████████████▋                                                 | 62000/118964 [00:07<00:06, 8319.54 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  53%|██████████████████████████████████████████████████████▌                                                | 63000/118964 [00:07<00:06, 8246.50 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  54%|███████████████████████████████████████████████████████▍                                               | 64000/118964 [00:07<00:06, 8288.67 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  55%|████████████████████████████████████████████████████████▎                                              | 65000/118964 [00:08<00:06, 8352.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  55%|█████████████████████████████████████████████████████████▏                                             | 66000/118964 [00:08<00:06, 8306.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  56%|██████████████████████████████████████████████████████████                                             | 67000/118964 [00:08<00:06, 8382.08 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  57%|██████████████████████████████████████████████████████████▊                                            | 68000/118964 [00:08<00:06, 8453.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  58%|███████████████████████████████████████████████████████████▋                                           | 69000/118964 [00:08<00:05, 8383.56 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  59%|████████████████████████████████████████████████████████████▌                                          | 70000/118964 [00:08<00:05, 8387.23 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  60%|█████████████████████████████████████████████████████████████▍                                         | 71000/118964 [00:08<00:05, 8382.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  61%|██████████████████████████████████████████████████████████████▎                                        | 72000/118964 [00:08<00:05, 8306.00 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  61%|███████████████████████████████████████████████████████████████▏                                       | 73000/118964 [00:09<00:05, 8349.87 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  62%|████████████████████████████████████████████████████████████████                                       | 74000/118964 [00:09<00:05, 8342.88 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  63%|████████████████████████████████████████████████████████████████▉                                      | 75000/118964 [00:09<00:05, 8322.58 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  64%|█████████████████████████████████████████████████████████████████▊                                     | 76000/118964 [00:09<00:05, 8363.12 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  65%|██████████████████████████████████████████████████████████████████▋                                    | 77000/118964 [00:09<00:05, 8381.36 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  66%|███████████████████████████████████████████████████████████████████▌                                   | 78000/118964 [00:09<00:04, 8316.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  66%|████████████████████████████████████████████████████████████████████▍                                  | 79000/118964 [00:09<00:04, 8370.30 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  67%|█████████████████████████████████████████████████████████████████████▎                                 | 80000/118964 [00:09<00:04, 8366.57 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  68%|██████████████████████████████████████████████████████████████████████▏                                | 81000/118964 [00:10<00:04, 8287.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  69%|██████████████████████████████████████████████████████████████████████▉                                | 82000/118964 [00:10<00:04, 8321.76 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  70%|███████████████████████████████████████████████████████████████████████▊                               | 83000/118964 [00:10<00:04, 8320.78 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  71%|████████████████████████████████████████████████████████████████████████▋                              | 84000/118964 [00:10<00:04, 8278.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  71%|█████████████████████████████████████████████████████████████████████████▌                             | 85000/118964 [00:10<00:04, 8366.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  72%|██████████████████████████████████████████████████████████████████████████▍                            | 86000/118964 [00:10<00:03, 8406.51 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  73%|███████████████████████████████████████████████████████████████████████████▎                           | 87000/118964 [00:10<00:03, 8312.57 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  74%|████████████████████████████████████████████████████████████████████████████▏                          | 88000/118964 [00:10<00:03, 8365.72 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  75%|█████████████████████████████████████████████████████████████████████████████                          | 89000/118964 [00:10<00:03, 8392.05 examples/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  76%|█████████████████████████████████████████████████████████████████████████████▉                         | 90000/118964 [00:11<00:03, 8284.53 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  76%|██████████████████████████████████████████████████████████████████████████████▊                        | 91000/118964 [00:11<00:03, 8322.91 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  77%|███████████████████████████████████████████████████████████████████████████████▋                       | 92000/118964 [00:11<00:03, 8363.41 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  78%|████████████████████████████████████████████████████████████████████████████████▌                      | 93000/118964 [00:11<00:03, 8285.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  79%|█████████████████████████████████████████████████████████████████████████████████▍                     | 94000/118964 [00:11<00:04, 5946.04 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  80%|██████████████████████████████████████████████████████████████████████████████████▎                    | 95000/118964 [00:11<00:03, 6517.94 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  81%|███████████████████████████████████████████████████████████████████████████████████                    | 96000/118964 [00:11<00:03, 6911.42 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  82%|███████████████████████████████████████████████████████████████████████████████████▉                   | 97000/118964 [00:12<00:02, 7327.44 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  82%|████████████████████████████████████████████████████████████████████████████████████▊                  | 98000/118964 [00:12<00:02, 7581.13 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  83%|█████████████████████████████████████████████████████████████████████████████████████▋                 | 99000/118964 [00:12<00:02, 7649.84 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  84%|█████████████████████████████████████████████████████████████████████████████████████▋                | 100000/118964 [00:12<00:02, 6941.87 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  85%|██████████████████████████████████████████████████████████████████████████████████████▌               | 101000/118964 [00:12<00:02, 7237.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  86%|███████████████████████████████████████████████████████████████████████████████████████▍              | 102000/118964 [00:12<00:02, 7433.05 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  87%|████████████████████████████████████████████████████████████████████████████████████████▎             | 103000/118964 [00:12<00:02, 7420.27 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  87%|█████████████████████████████████████████████████████████████████████████████████████████▏            | 104000/118964 [00:13<00:01, 7627.53 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  88%|██████████████████████████████████████████████████████████████████████████████████████████            | 105000/118964 [00:13<00:01, 7770.68 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  89%|██████████████████████████████████████████████████████████████████████████████████████████▉           | 106000/118964 [00:13<00:01, 7948.33 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  90%|███████████████████████████████████████████████████████████████████████████████████████████▋          | 107000/118964 [00:13<00:01, 8076.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  91%|████████████████████████████████████████████████████████████████████████████████████████████▌         | 108000/118964 [00:13<00:01, 8089.06 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  92%|█████████████████████████████████████████████████████████████████████████████████████████████▍        | 109000/118964 [00:13<00:01, 8246.20 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  92%|██████████████████████████████████████████████████████████████████████████████████████████████▎       | 110000/118964 [00:13<00:01, 8330.23 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  93%|███████████████████████████████████████████████████████████████████████████████████████████████▏      | 111000/118964 [00:13<00:00, 8189.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  94%|████████████████████████████████████████████████████████████████████████████████████████████████      | 112000/118964 [00:13<00:00, 8279.29 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  95%|████████████████████████████████████████████████████████████████████████████████████████████████▉     | 113000/118964 [00:14<00:00, 8324.37 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████▋    | 114000/118964 [00:14<00:00, 8025.11 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████▌   | 115000/118964 [00:14<00:00, 7942.03 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████▍  | 116000/118964 [00:14<00:00, 8105.90 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 117000/118964 [00:14<00:00, 8116.53 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏| 118000/118964 [00:14<00:00, 8195.31 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 118964/118964 [00:14<00:00, 8010.12 examples/s]\u001b[A\u001b[A\n",
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='5577' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  25/5577 03:42 < 14:55:11, 0.10 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 79\u001b[0m\n\u001b[1;32m     67\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     68\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     69\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     packing\u001b[38;5;241m=\u001b[39mpacking,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Save trained model\u001b[39;00m\n\u001b[1;32m     82\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(new_model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1599\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1900\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1900\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1903\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1904\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1906\u001b[0m ):\n\u001b[1;32m   1907\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1908\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:1853\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1853\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load dataset (you can process it here)\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bcedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"No me gsuta cuando me tratas de esa manera\"\n",
    "text = f\"\"\"<s>You are going to do a Spanish to English translation. Sentence: {sentence} [/INST]\"\"\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fb733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
