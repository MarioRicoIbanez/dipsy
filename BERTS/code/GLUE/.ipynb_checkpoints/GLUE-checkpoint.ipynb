{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deep_translator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, RobertaModel, get_linear_schedule_with_warmup\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/code/GLUE/utils.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader, RandomSampler\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeep_translator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleTranslator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deep_translator'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, RobertaModel, get_linear_schedule_with_warmup\n",
    "from utils import *\n",
    "from datasets import load_dataset\n",
    "import traceback\n",
    "import asyncio\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\"\"\"GLOBAL PARAMS\"\"\"\n",
    "MAX_LEN = 180\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS_KFOLD_FROZEN = 100\n",
    "LEARNING_RATE_KFOLD_FROZEN = 3e-4\n",
    "K_FOLDS_FROZEN = 2\n",
    "BATCH_SIZE = 16\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "\"DIRECTORIES\"\n",
    "SAVE_DIRECTORY_FROZEN = \"./GLUE/RoBERTa_entrenado_kfold\"\n",
    "SAVE_DIRECTORY_UNFROZEN = \"./GLUE/RoBERTa_entrenado_kfold_unfrozen_last_layer\"\n",
    "\n",
    "TYPED_STORAGE_WARNING = re.compile(\".TypedStorage is deprecated.\")\n",
    "FALLBACK_KERNEL_WARNING = re.compile(\".Using FallbackKernel: aten.cumsum.\")\n",
    "TRITON_RANDOM_WARNING = re.compile(\".using triton random, expect difference from eager.\")\n",
    "\n",
    "def warning_filter(message, category, filename, lineno, file=None, line=None):\n",
    "    if category == UserWarning and (TYPED_STORAGE_WARNING.match(str(message)) or FALLBACK_KERNEL_WARNING.match(str(message)) or TRITON_RANDOM_WARNING.match(str(message))):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "warnings.showwarning = warning_filter\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch._inductor.ir\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the GLUE dataset\n",
    "def load_glue_dataset(task_name):\n",
    "    dataset = load_dataset('glue', task_name)\n",
    "    return dataset\n",
    "\n",
    "# Preprocess the GLUE dataset\n",
    "def preprocess_glue_data(dataset, tokenizer, max_len):\n",
    "    def encode(example):\n",
    "        return tokenizer(example['sentence'], truncation=True, padding='max_length', max_length=max_len)\n",
    "\n",
    "    encoded_dataset = dataset.map(encode, batched=True)\n",
    "    return encoded_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
